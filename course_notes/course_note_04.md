# 书生大语言模型实战培训营第四次课程笔记

## 课程概述
- **讲师**: 李剑锋、汪周谦、王群，XTuner 贡献者
- - **内容**:
  - 微调理论讲解及 XTuner 介绍
  - XTuner 微调小助手个人认知实战
  - XTuner 微调 llava 图片理解多模态模型实战
- **视频**：https://b23.tv/QUhT6ni
- **课程文档**：https://github.com/InternLM/Tutorial/blob/camp2/xtuner/readme.md
- **作业文档**：https://github.com/InternLM/Tutorial/blob/camp2/xtuner/homework.md

## 微调理论讲解及 XTuner 介绍
- **微调** (Finetune) 是对预训练大模型进行特定任务或领域的调整，以提高模型在特定任务上的表现。
- **XTuner** 是一个低门槛的微调框架，支持多种生态适配，具有集成化微调工具，能够在较低显存配置下运行。

## XTuner 微调小助手个人认知实战
- **实战目标**: 使用XTuner微调一个小型的个人认知助手模型。
- **数据准备**: 通过脚本生成包含输入和输出对的JSON格式数据集。
- **模型选择**: 使用InternLM2-Chat-1.8B作为基础模型进行微调。
- **配置文件**: 选择与任务匹配的配置文件，并根据需要进行修改。
- **训练过程**: 使用XTuner进行模型训练，并通过DeepSpeed技术加速训练过程。

## XTuner 微调 llava 图片理解多模态模型实战
- **多模态LLM**: 结合文本和图像信息，提升模型对图片内容的理解能力。
- **LLaVA方案**: 通过训练Image Projector，使LLM具备视觉能力，能够对图片进行描述和理解。
- **训练阶段**: 分为预训练和微调两个阶段，预训练阶段使用网络爬取的数据，微调阶段使用高质量监督数据。

## 总结
本次课程深入讲解了微调理论和XTuner框架的使用，并通过两个实战案例展示了如何微调大模型以适应特定任务。通过学习，我们了解了微调的基本概念、XTuner框架的特点和使用方法，以及如何构建和训练多模态模型。这些知识和技能对于提升大模型在实际应用中的表现至关重要。
